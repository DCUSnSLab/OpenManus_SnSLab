# Global LLM configuration
[llm]
#model = "llama3.3:latest"
#base_url = "http://203.250.33.193:11434/v1"
#api_key = "test"
#max_tokens = 4096
#temperature = 0.0

model = "qwen2.5:72b"
base_url = "http://203.250.33.193:11436/v1"
api_key = "test"
max_tokens = 8192
temperature = 0.0

#model = "qwq:32b"
#base_url = "http://203.250.33.193:11437/v1"
#api_key = "test"
#max_tokens = 4096
#temperature = 0.0

# 딥시크는 지원 안됨..
#model = "deepseek-r1:70b"
#base_url = "http://203.250.33.193:11435/v1"
#api_key = "test"
#max_tokens = 8192
#temperature = 0.0

# [llm] #AZURE OPENAI:
# api_type= 'azure'
# model = "YOUR_MODEL_NAME" #"gpt-4o-mini"
# base_url = "{YOUR_AZURE_ENDPOINT.rstrip('/')}/openai/deployments/{AZURE_DEPOLYMENT_ID}"
# api_key = "AZURE API KEY"
# max_tokens = 8096
# temperature = 0.0
# api_version="AZURE API VERSION" #"2024-08-01-preview"

# Optional configuration for specific LLM models
[llm.vision]
model = "claude-3-5-sonnet"
base_url = "https://api.openai.com/v1"
api_key = "sk-..."
